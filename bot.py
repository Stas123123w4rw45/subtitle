# -*- coding: utf-8 -*-
import os
import sys
import threading
import subprocess
import tempfile
import time
import shutil
import logging
import asyncio
import re
import json
import gc
from groq import Groq 

# Settings file path - use Railway Volume if available, fallback to local
# On Railway with Volume mounted at /app/data, this will persist across restarts
SETTINGS_DIR = "/app/data" if os.path.exists("/app/data") else "."
SETTINGS_FILE = os.path.join(SETTINGS_DIR, "user_settings.json")

# Ensure settings directory exists
try:
    os.makedirs(SETTINGS_DIR, exist_ok=True)
    # Test write permissions
    test_file = os.path.join(SETTINGS_DIR, ".test_write")
    with open(test_file, 'w') as f:
        f.write("test")
    os.remove(test_file)
    print(f"‚úÖ Settings directory ready: {SETTINGS_DIR}")
except Exception as e:
    print(f"‚ö†Ô∏è Settings directory issue: {e}, using current directory")
    SETTINGS_FILE = "user_settings.json"

def load_settings(chat_id):
    try:
        if os.path.exists(SETTINGS_FILE):
            with open(SETTINGS_FILE, 'r') as f:
                data = json.load(f)
                return data.get(str(chat_id), {})
    except Exception as e:
        print(f"Error loading settings: {e}")  # Use print before logging is configured
    return {}

def save_settings(chat_id, settings):
    try:
        data = {}
        if os.path.exists(SETTINGS_FILE):
            with open(SETTINGS_FILE, 'r') as f:
                try: data = json.load(f)
                except: pass
        
        data[str(chat_id)] = settings
        
        with open(SETTINGS_FILE, 'w') as f:
            json.dump(data, f, indent=2)  # Added indent for readability
    except Exception as e:
        print(f"Error saving settings: {e}")  

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes,
    ConversationHandler, CallbackQueryHandler
)
from http.server import HTTPServer, BaseHTTPRequestHandler

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
log = logging.getLogger(__name__)

# --- –í–ê–®–Ü –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø ---
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
DEFAULT_CRF = "20" 
WORDS_PER_LINE = 2 
MAX_LINES_PER_PAGE = 1 
# -------------------------

# --- –°—Ç–∞–Ω–∏ –¥–ª—è –¥—ñ–∞–ª–æ–≥—É ---
STATE_RECEIVE_VIDEO, STATE_RECEIVE_EDIT = range(2)

# --- –§—É–Ω–∫—Ü—ñ—ó-—Ö–µ–ª–ø–µ—Ä–∏ ---

def find_ffmpeg():
    # 1. Check local folder (priority for portable setup)
    local_ffmpeg = os.path.join(os.getcwd(), "ffmpeg")
    if os.path.isfile(local_ffmpeg) and os.access(local_ffmpeg, os.X_OK):
        log.info(f"Using local ffmpeg: {local_ffmpeg}")
        return local_ffmpeg
        
    # 2. Check PATH
    if shutil.which("ffmpeg"):
        log.info("Using ffmpeg from PATH")
        return "ffmpeg"
        
    log.error("FFmpeg not found!")
    return "ffmpeg" # Fallback

def escape_for_subtitles_filter(path):
    p = os.path.abspath(path)
    if os.name == 'nt':
        p = p.replace("\\", "/").replace(":", "\\:")
    return p

def create_rounded_rect_path(w, h, r):
    """Generates ASS vector path for a rounded rectangle centered at 0,0."""
    hw = w / 2
    hh = h / 2
    r = min(r, hw, hh)
    
    # Start top-left (after radius)
    path = f"m {-hw + r} {-hh} l {hw - r} {-hh} "
    # Top-right corner
    path += f"b {hw} {-hh} {hw} {-hh} {hw} {-hh + r} "
    # Right edge
    path += f"l {hw} {hh - r} "
    # Bottom-right corner
    path += f"b {hw} {hh} {hw} {hh} {hw - r} {hh} "
    # Bottom edge
    path += f"l {-hw + r} {hh} "
    # Bottom-left corner
    path += f"b {-hw} {hh} {-hw} {hh} {-hw} {hh - r} "
    # Left edge
    path += f"l {-hw} {-hh + r} "
    # Top-left corner
    path += f"b {-hw} {-hh} {-hw} {-hh} {-hw + r} {-hh} "
    
    return path

def ass_time(sec: float) -> str:
    h = int(sec // 3600); m = int((sec % 3600) // 60); s = int(sec % 60); cs = int(round((sec - int(sec))*100))
    return f"{h:01d}:{m:02d}:{s:02d}.{cs:02d}"

def escape_ass_text(txt: str) -> str:
    return txt.replace("{", r"\{").replace("}", r"\}")

# --- [–õ–û–ì–Ü–ö–ê GROQ API] ---

def transcribe_with_groq(file_path):
    if not GROQ_API_KEY:
        raise ValueError("–ù–µ –≤–∫–∞–∑–∞–Ω–æ GROQ_API_KEY!")

    client = Groq(api_key=GROQ_API_KEY)
    
    with open(file_path, "rb") as file:
        transcription = client.audio.transcriptions.create(
            file=(os.path.basename(file_path), file.read()),
            model="whisper-large-v3",
            response_format="verbose_json",
            timestamp_granularities=["word"],
            language="uk"
        )

    all_words = []
    full_text = transcription.text
    
    if hasattr(transcription, 'words'):
        for w in transcription.words:
            all_words.append((float(w['start']), float(w['end']), w['word'].strip()))
        
    return full_text, all_words

# --- [–õ–û–ì–Ü–ö–ê –°–ò–ù–•–†–û–ù–Ü–ó–ê–¶–Ü–á] ---

def norm_token(t: str) -> str:
    return re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø0-9—ñ—ó—î“ë–Ü–á–Ñ“ê']+", "", t).lower()

def _parse_transcript_for_tokens(raw_text):
    tokens = []
    manual_starts = set()
    i = 0
    n = len(raw_text)
    next_is_line_start = False
    while i < n:
        ch = raw_text[i]
        if ch.isspace():
            j = i
            while j < n and raw_text[j].isspace(): j += 1
            if '  ' in raw_text[i:j] or '\n' in raw_text[i:j]:
                next_is_line_start = True
            i = j
            continue
        j = i
        while j < n and (not raw_text[j].isspace()): j += 1
        word = raw_text[i:j]
        if word:
            tokens.append(word)
            if next_is_line_start:
                manual_starts.add(len(tokens)-1)
                next_is_line_start = False
        i = j
    return tokens, manual_starts

def _align_tokens(src_word_segments, tgt_tokens):
    if not src_word_segments: return []
    src_words = [(float(t0), float(t1), w) for (t0,t1,w) in src_word_segments]
    src_norm = [norm_token(w) for (_,_,w) in src_words]
    tgt_norm = [norm_token(t) for t in tgt_tokens]
    n, m = len(src_norm), len(tgt_norm)
    if m == 0: return []
    if n == 0: return [(0.0, 0.0)] * m

    dp = [[(0, 'S')] * (m + 1) for _ in range(n + 1)]
    for i in range(n + 1): dp[i][0] = (i, 'D')
    for j in range(1, m + 1): dp[0][j] = (j, 'I')
    
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            cost = 0 if (src_norm[i-1] == tgt_norm[j-1] and src_norm[i-1]) else 1
            sub_cost = dp[i-1][j-1][0] + cost
            del_cost = dp[i-1][j][0] + 1
            ins_cost = dp[i][j-1][0] + 1
            if sub_cost <= del_cost and sub_cost <= ins_cost: dp[i][j] = (sub_cost, 'M')
            elif del_cost < ins_cost: dp[i][j] = (del_cost, 'D')
            else: dp[i][j] = (ins_cost, 'I')

    mapping = [-1] * m
    i, j = n, m
    while i > 0 or j > 0:
        op = dp[i][j][1]
        if op == 'M':
            if j > 0: mapping[j-1] = i-1
            i -= 1; j -= 1
        elif op == 'D': i -= 1
        elif op == 'I':
            if j > 0: mapping[j-1] = max(0, i - 1)
            j -= 1
        else: break
            
    token_times = []
    for j in range(m):
        mi = mapping[j]
        if mi >= 0 and mi < len(src_words):
            token_times.append((src_words[mi][0], src_words[mi][1]))
        else:
            ref_i = -1
            if j > 0 and mapping[j-1] >= 0: ref_i = mapping[j-1]
            elif j < m - 1 and mapping[j+1] >= 0: ref_i = mapping[j+1]
            elif j > 0: ref_i = mapping[j-1]
            if ref_i >= 0 and ref_i < len(src_words):
                t_ref = (src_words[ref_i][0] + src_words[ref_i][1]) / 2.0
                token_times.append((t_ref, t_ref + 0.1))
            else: token_times.append((0.0, 0.1))
    return token_times

def _smart_layout(tokens, wpl=2, max_lines=1, fontsize=93):
    """
    Smart layout that respects:
    1. Punctuation (force page break after . ! ?)
    2. Max Width (18% margin -> ~700px safe zone)
    3. WPL (soft limit)
    4. Max Lines (hard limit)
    """
    SAFE_WIDTH = 1080 * 0.64  # 1080 - 18%*2 margins ~= 690px
    AVG_CHAR_WIDTH = fontsize * 0.55 # Heuristic
    
    pages = []
    current_page = []
    current_line = []
    current_line_width = 0
    
    for i, token in enumerate(tokens):
        # Clean token for width calc
        clean_t = re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø0-9—ñ—ó—î“ë–Ü–á–Ñ“ê']+", "", token)
        word_width = len(clean_t) * AVG_CHAR_WIDTH
        
        # Check if we need to wrap to new line
        # 1. WPL limit reached
        # 2. Width limit reached
        force_new_line = False
        if len(current_line) >= wpl:
            force_new_line = True
        elif current_line_width + word_width > SAFE_WIDTH:
            force_new_line = True
            
        if force_new_line:
            if current_line:
                current_page.append(current_line)
            current_line = []
            current_line_width = 0
            
            # Check if page is full
            if len(current_page) >= max_lines:
                pages.append(current_page)
                current_page = []
        
        # Add to current line
        current_line.append(i)
        current_line_width += word_width + (fontsize * 0.2) # Add space width
        
        # Check for sentence ending punctuation
        # We look at the raw token (it might have punctuation)
        if token and token[-1] in ".!?,:‚Äî-":
            # Finish line
            current_page.append(current_line)
            current_line = []
            current_line_width = 0
            # Finish page
            pages.append(current_page)
            current_page = []
            
    # Flush remaining
    if current_line:
        current_page.append(current_line)
    if current_page:
        pages.append(current_page)
        
    return pages

def _events_from_layout(tokens, token_times, manual_starts):
    n = len(tokens)
    if n == 0 or not token_times or len(token_times) != n: return []
    mids = []
    for j in range(n - 1):
        c1 = (token_times[j][0] + token_times[j][1]) / 2.0
        c2 = (token_times[j+1][0] + token_times[j+1][1]) / 2.0
        mids.append((c1 + c2) / 2.0)
    
    pages = _pages_from_manual_or_auto(len(tokens), manual_starts, WORDS_PER_LINE, MAX_LINES_PER_PAGE)
    events = []
    for lines in pages:
        inds = [j for ln in lines for j in ln]
        if not inds: continue
        if inds[-1] >= n or inds[0] >= n: continue
        t0_word = token_times[inds[0]][0]
        t1_word = token_times[inds[-1]][1]
        left_bound = t0_word
        right_bound = t1_word
        if inds[0] - 1 >= 0: left_bound = max(left_bound, mids[inds[0] - 1])
        if inds[-1] < n - 1: right_bound = min(right_bound, mids[inds[-1]])
        
        min_sec = 0.9 
        if right_bound - left_bound < min_sec: right_bound = left_bound + min_sec
        t0, t1 = left_bound, right_bound

        parts = []
        for ln in lines:
            clean_words = []
            for j in ln:
                clean_word = re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø0-9—ñ—ó—î“ë–Ü–á–Ñ“ê']+", "", tokens[j])
                if clean_word: clean_words.append(clean_word.upper())
            if clean_words: parts.append(escape_ass_text(" ".join(clean_words)))
        if not parts: continue
        txt = r"\N".join(parts)
        events.append((t0, t1, txt))
        
    if not events: return []
    fixed_events = []
    for i in range(len(events)):
        (t0, t1, txt) = events[i]
        next_t0 = float('inf')
        if i + 1 < len(events): next_t0 = events[i+1][0]
        if t1 > next_t0: t1 = next_t0
        if t1 <= t0: t1 = t0 + 0.1
        fixed_events.append((t0, t1, txt))
    return fixed_events

def generate_styled_events(tokens, token_times, style_settings):
    """
    Generates ASS events based on layout settings (WPL, Max Lines) and applies
    effects (Karaoke, Animation) if enabled.
    """
    wpl = style_settings.get('wpl', WORDS_PER_LINE)
    max_lines = style_settings.get('max_lines', MAX_LINES_PER_PAGE)
    karaoke = style_settings.get('karaoke', False)
    animation = style_settings.get('animation', False)
    # highlight_color is applied via \c tag. Default is taken from settings or hardcoded if missing.
    highlight_color = style_settings.get('highlight_color_value', '&H0000FFFF') # Yellow default for karaoke
    
    # Box Settings
    box_enabled = style_settings.get('box_enabled', False)
    box_color = str(style_settings.get('box_color_value', '&H00FFFFFF'))
    box_opacity_hex = str(style_settings.get('box_opacity', '&H00'))

    n = len(tokens)
    if n == 0 or not token_times: return []

    # 1. Calculate Layout (Pages/Lines)
    # Use smart layout
    fontsize = style_settings.get('fontsize', 93)
    pages = _smart_layout(tokens, wpl, max_lines, fontsize)

    events = []
    
    # For box positioning
    target_w = 1080
    
    for page_lines in pages:
        if not page_lines: continue
        
        # Flatten lines to get start/end indices for the whole page/event
        all_indices = [idx for line in page_lines for idx in line]
        if not all_indices: continue
        
        start_idx = all_indices[0]
        end_idx = all_indices[-1]
        
        if start_idx >= len(token_times) or end_idx >= len(token_times): continue

        t_start = token_times[start_idx][0]
        t_end = token_times[end_idx][1]
        
        # Pad time slightly
        t_start = max(0, t_start - 0.1)
        t_end = t_end + 0.1
        duration_ms = (t_end - t_start) * 1000

        # Build Text & Boxes
        lines_text = []
        page_boxes = []
        
        # Calculate total width of each line to center it
        # This is an approximation for box positioning
        
        for line_idx, line_indices in enumerate(page_lines):
            line_parts = []
            
            # Calculate total line width for centering
            total_line_width = 0
            word_widths = []
            space_width = fontsize * 0.2
            
            for idx in line_indices:
                if idx >= len(tokens): 
                    word_widths.append(0)
                    continue
                token = tokens[idx]
                clean_token = re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø0-9—ñ—ó—î“ë–Ü–á–Ñ“ê']+", "", token)
                # Heuristic width
                ww = len(clean_token) * (fontsize * 0.55) # Same heuristic as smart layout
                word_widths.append(ww)
                total_line_width += ww + space_width
            
            if total_line_width > 0: total_line_width -= space_width
            
            # Start X (Centered)
            current_x = (target_w - total_line_width) / 2
            
            prev_box_x = None
            
            for i, idx in enumerate(line_indices):
                if idx >= len(tokens): continue
                
                token = tokens[idx]
                clean_token = re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø0-9—ñ—ó—î“ë–Ü–á–Ñ“ê']+", "", token)
                if not clean_token: continue
                
                word_width = word_widths[i]
                
                # Word Timing
                w_start = token_times[idx][0]
                w_end = token_times[idx][1]
                
                # Relative times in ms for tags
                rel_start = int((w_start - t_start) * 1000)
                rel_end = int((w_end - t_start) * 1000)
                
                prefix = ""
                suffix = ""
                
                # --- BACKGROUND (Box) via Vector Drawing ---
                if box_enabled:
                    pad_x = 5
                    pad_y = 2
                    
                    b_w = int(word_width + pad_x * 2)
                    b_h = int(fontsize + pad_y * 2)
                    
                    # Box Center X = current_x + word_width / 2
                    # [RESTORED] +150px offset from "Morning Version"
                    box_center_x = int(current_x + word_width / 2 + 150)
                    
                    box_data = {
                        'x': box_center_x,
                        'w': b_w,
                        'h': b_h,
                        'line_idx': line_idx,
                        'word_idx_in_line': i,
                        'abs_start': w_start,
                        'abs_end': w_end,
                        'opacity': box_opacity_hex,
                        'color': box_color,
                        'prev_x': prev_box_x
                    }
                    page_boxes.append(box_data)
                    prev_box_x = box_center_x
                
                # Apply Effects
                if karaoke:
                    # Karaoke: Start with normal color, highlight during word, return to normal
                    # Initial state: normal color
                    normal_color = style_settings.get('fontcolor', '&H00FFFFFF')
                    
                    # At word start: transition to highlight
                    # At word end: transition back to normal
                    prefix += f"{{\\1c{normal_color}}}{{\\t({rel_start},{rel_start},\\1c{highlight_color})}}{{\\t({rel_end},{rel_end},\\1c{normal_color})}}"

                if animation:
                    # Animation: Start at 100%, scale up to 105% during word, back to 100%
                    # Initial state: normal scale
                    mid = (rel_start + rel_end) // 2
                    prefix += f"{{\\fscx100\\fscy100}}{{\\t({rel_start},{mid},\\fscx105\\fscy105)}}{{\\t({mid},{rel_end},\\fscx100\\fscy100)}}"

                line_parts.append(f"{prefix}{clean_token.upper()}{suffix}")
                
                current_x += word_width + space_width
            
            if line_parts:
                lines_text.append(" ".join(line_parts))
        
        if lines_text:
            full_text = r"\N".join(lines_text)
            events.append({'start': t_start, 'end': t_end, 'fg': full_text, 'boxes': page_boxes})
    
    # [FIX] Prevent event overlaps
    for i in range(len(events) - 1):
        if events[i]['end'] > events[i+1]['start']:
            events[i]['end'] = events[i+1]['start']
        if events[i]['end'] <= events[i]['start']:
            events[i]['end'] = events[i]['start'] + 0.1

    return events

def write_ass_styled(out_path, events, style_settings):
    log.info(f"–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Å—Ç–∏–ª—ñ–∑–æ–≤–∞–Ω–æ–≥–æ ASS —Ñ–∞–π–ª—É...")
    
    y_offset_percent = style_settings.get('margin_bottom', 30)
    target_w = 1080; target_h = 1920
    y_pos = int(target_h - (target_h * (y_offset_percent / 100.0)))
    x_pos = target_w // 2
    
    fontsize = style_settings.get('fontsize', 93)
    fontcolor = style_settings.get('fontcolor', '&H00FFFFFF')
    fontname = style_settings.get('fontname', 'Peace Sans')
    
    # Shadow and Outline settings
    shadow_size = 0 if not style_settings.get('shadow_enabled', True) else 4
    outline_size = 0 if not style_settings.get('outline_enabled', True) else 3
    
    # Main Style
    style_string = (
        f"Style: Default,{fontname},{fontsize},"
        f"{fontcolor},&H00FFFFFF,&H00000000,&H64000000,"
        f"1,0,0,0,100,100,0,0,1,"
        f"{outline_size},{shadow_size},5," # Outline, Shadow, Alignment (5=Center)
        "10,10,10,0"
    )

    ass = ["[Script Info]", "ScriptType: v4.00+", f"PlayResX: {target_w}", f"PlayResY: {target_h}",
           "ScaledBorderAndShadow: yes\n", "[V4+ Styles]",
           "Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, "
           "Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, "
           "Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding",
           style_string + "\n", "[Events]",
           "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text"]
           
    if not events:
        ass.append(f"Dialogue: 0,0:00:00.00,0:00:05.00,Default,,0000,0000,0000,,{{\\pos({x_pos},{y_pos})}}–ü–û–ú–ò–õ–ö–ê: –ù–ï –ó–ù–ê–ô–î–ï–ù–û –¢–ï–ö–°–¢–£")
    
    for ev in events:
        # ev is a dict: {'start', 'end', 'fg', 'boxes': []}
        t0 = ev['start']
        t1 = ev['end']
        text_fg = ev['fg']
        boxes = ev.get('boxes', [])
        
        # Dynamic Vertical Centering based on actual line count
        num_lines = text_fg.count(r"\N") + 1
        max_lines_setting = style_settings.get('max_lines', 1)
        
        # Calculate base position
        current_y = y_pos
        
        # If fewer lines than max, shift to center vertically
        if num_lines < max_lines_setting:
            # IMPORTANT: Alignment 5 (center-center) means \pos(x,y) places text
            # with its CENTER at position y, not its baseline or top.
            # So we need to calculate where the center should be.
            
            # Calculate the total vertical space for max_lines
            # Line spacing is 1.2 * fontsize between lines
            line_spacing = fontsize * 1.2
            
            # For max_lines, the vertical range from top of first line to bottom of last line:
            # If max_lines=2: range from line1_center to line2_center = 1 * line_spacing
            # If max_lines=3: range from line1_center to line3_center = 2 * line_spacing
            max_range = (max_lines_setting - 1) * line_spacing
            
            # For num_lines=1 (single line), we want it centered in that range
            # The center of the range is at: y_pos - (max_range / 2)
            # This places the single line exactly between where line1 and line_max would be
            
            total_shift = max_range / 2
            current_y = int(y_pos - total_shift)
            
            # Debug logging
            log.info(f"üîç Vertical Centering:")
            log.info(f"  Lines: {num_lines}/{max_lines_setting} (actual/max)")
            log.info(f"  Base Y: {y_pos}, Max range: {max_range:.1f}, Shift: {total_shift:.1f}")
            log.info(f"  Final Y: {current_y} (this is CENTER of text due to Alignment 5)")
            
        s_time = ass_time(t0)
        e_time = ass_time(t1)
        
        # Layer 0: Background Boxes
        for box in boxes:
            line_idx = box['line_idx']
            
            # Calculate Y for this line
            # Line spacing 1.2
            line_y = current_y - (num_lines - 1 - line_idx) * (fontsize * 1.2)
            box_y = int(line_y + fontsize * 0.5)
            
            bx = box['x']
            bw = box['w']
            bh = box['h']
            
            # Use ABSOLUTE timestamps for this box
            box_start = ass_time(box['abs_start'])
            box_end = ass_time(box['abs_end'])
            
            # Vector Rect (Centered at 0,0)
            rect = create_rounded_rect_path(bw, bh, 15)
            
            # [CRITICAL] Use \c for vector fill color
            style = f"\\c{box['color']}\\bord0\\shad0\\blur0\\alpha&HFF&"
            
            # Animation: Sliding
            anim = f"{{\\alpha{box['opacity']}}}"
            duration_ms = int((box['abs_end'] - box['abs_start']) * 1000)
            
            # Sliding: Use \move if there's a previous box
            if box['prev_x'] is not None and box['word_idx_in_line'] > 0:
                prev_x = box['prev_x']
                prev_y = box_y
                slide_duration = min(150, duration_ms // 2)
                pos = f"\\move({prev_x},{prev_y},{bx},{box_y},0,{slide_duration})"
            else:
                pos = f"\\pos({bx},{box_y})"
            
            ass_line = f"Dialogue: 0,{box_start},{box_end},Default,,0000,0000,0000,,{{{pos}}}{{\\p1}}{style}{anim}{rect}{{\\p0}}"
            ass.append(ass_line)
            
        # Layer 1: Foreground (Text)
        ass_line = f"Dialogue: 1,{s_time},{e_time},Default,,0000,0000,0000,,{{\\pos({x_pos},{current_y})}}{text_fg}"
        ass.append(ass_line)
        
    with open(out_path, "w", encoding="utf-8") as f:
        f.write("\n".join(ass))

def process_video_with_edits(video_path, all_words_original, edited_text, crf, style_settings):
    tokens, manual_starts = _parse_transcript_for_tokens(edited_text) 
    tokens_for_align = [re.sub(r"[^\w\s']+", "", t) for t in tokens]
    token_times = _align_tokens(all_words_original, tokens_for_align)
    # Generate events using new logic
    events = generate_styled_events(tokens, token_times, style_settings)
    
    tmp_dir = tempfile.mkdtemp(prefix="sub_bot_")
    ass_path = os.path.join(tmp_dir, "subs.ass")
    write_ass_styled(ass_path, events, style_settings) 

    ff = find_ffmpeg()
    basename = os.path.splitext(os.path.basename(video_path))[0]
    out_path = os.path.join(tmp_dir, f"{basename}_subs.mp4")
    sub_escaped = escape_for_subtitles_filter(ass_path)
    fontsdir_path = os.path.abspath("fonts")
    fontsdir_escaped = escape_for_subtitles_filter(fontsdir_path)
    
    # [!!! –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø –®–†–ò–§–¢–Ü–í !!!]
    # –Ø–≤–Ω–æ –≤–∫–∞–∑—É—î–º–æ –ø–∞–ø–∫—É —à—Ä–∏—Ñ—Ç—ñ–≤, —è–∫—â–æ –≤–æ–Ω–∞ —î
    if os.path.exists(fontsdir_path):
        vf_filter = f"subtitles='{sub_escaped}':fontsdir='{fontsdir_escaped}'"
    else:
        vf_filter = f"subtitles='{sub_escaped}'"

    cmd = [
        ff, "-y", "-i", video_path, "-vf", f"scale='min(1080,iw)':-2,{vf_filter}",
        "-c:v", "libx264", 
        "-crf", "23", # –¢—Ä–æ—Ö–∏ –∑–±—ñ–ª—å—à—É—î–º–æ CRF –¥–ª—è –º–µ–Ω—à–æ–≥–æ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (–±—É–ª–æ 20)
        "-preset", "superfast", # superfast –º–µ–Ω—à–µ —ó—Å—Ç—å –ø–∞–º'—è—Ç—ñ –Ω—ñ–∂ ultrafast —ñ–Ω–æ–¥—ñ, –∞–±–æ —Ç–∞–∫ —Å–∞–º–æ
        "-threads", "2", # –û–ë–ú–ï–ñ–ï–ù–ù–Ø –ü–û–¢–û–ö–Ü–í –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó RAM
        "-max_muxing_queue_size", "1024",
        "-movflags", "+faststart",
        "-c:a", "copy",
        out_path
    ]
    
    log.info(f"–ó–∞–ø—É—Å–∫ FFmpeg: {' '.join(cmd)}")
    proc = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8')
    
    if proc.returncode != 0 or not os.path.isfile(out_path):
        log.error(f"–ü–æ–º–∏–ª–∫–∞ FFmpeg:\n{proc.stdout[-1500:]}")
        raise RuntimeError(f"FFmpeg –∑–∞–≤–µ—Ä—à–∏–≤—Å—è –∑ –ø–æ–º–∏–ª–∫–æ—é (–∫–æ–¥ {proc.returncode}).")

    return out_path, tmp_dir

def get_video_duration(file_path):
    """Returns video duration in seconds using ffprobe."""
    try:
        # Try using ffprobe if available, otherwise estimate or fail
        # We can use ffmpeg to get duration from stderr
        ff = find_ffmpeg()
        cmd = [ff, "-i", file_path]
        result = subprocess.run(cmd, stderr=subprocess.PIPE, stdout=subprocess.DEVNULL, text=True, encoding='utf-8')
        # Search for "Duration: 00:00:05.00"
        match = re.search(r"Duration: (\d{2}):(\d{2}):(\d{2}\.\d{2})", result.stderr)
        if match:
            h, m, s = map(float, match.groups())
            return h * 3600 + m * 60 + s
    except Exception as e:
        log.error(f"Error getting duration: {e}")
    return 0

def get_video_resolution(file_path):
    """Returns video width and height."""
    try:
        ff = find_ffmpeg()
        cmd = [ff, "-i", file_path]
        result = subprocess.run(cmd, stderr=subprocess.PIPE, stdout=subprocess.DEVNULL, text=True, encoding='utf-8')
        # Search for resolution like "1920x1080" or "1080x1920"
        match = re.search(r"(\d{3,4})x(\d{3,4})", result.stderr)
        if match:
            width = int(match.group(1))
            height = int(match.group(2))
            return width, height
    except Exception as e:
        log.error(f"Error getting resolution: {e}")
    return None, None

def compress_video(input_path, target_size_mb=49.0):
    """
    Compresses video using intelligent two-pass strategy:
    1. First attempt: Compress at original resolution (Full HD if possible)
    2. If result > 49MB: Compress again at 720p
    
    This preserves quality for videos that can be compressed without resolution reduction.
    """
    log.info(f"Compressing {input_path} to {target_size_mb}MB...")
    
    duration = get_video_duration(input_path)
    if duration <= 0:
        log.error("Could not determine duration for compression.")
        return input_path # Return original if fail

    width, height = get_video_resolution(input_path)
    
    # Calculate target bitrate
    # Size = (VideoBitrate + AudioBitrate) * Duration / 8
    # TargetBits = TargetMB * 8 * 1024 * 1024
    # TargetBitrate = TargetBits / Duration
    
    target_total_bitrate_kbit = (target_size_mb * 8 * 1024) / duration
    audio_bitrate_kbit = 128
    video_bitrate_kbit = target_total_bitrate_kbit - audio_bitrate_kbit
    
    if video_bitrate_kbit < 100: video_bitrate_kbit = 100 # Minimum floor
    
    log.info(f"Duration: {duration}s, Target Bitrate: {video_bitrate_kbit:.0f}k")
    
    ff = find_ffmpeg()
    dir_name = os.path.dirname(input_path)
    base_name = os.path.splitext(os.path.basename(input_path))[0]
    
    # PASS 1: Try compressing at original resolution (preserve Full HD)
    log.info("Pass 1: Attempting compression at original resolution...")
    out_path_hd = os.path.join(dir_name, f"{base_name}_compressed_hd.mp4")
    
    cmd_hd = [
        ff, "-y", "-i", input_path,
        "-c:v", "libx264",
        "-b:v", f"{video_bitrate_kbit}k",
        "-maxrate", f"{video_bitrate_kbit * 1.5}k",
        "-bufsize", f"{video_bitrate_kbit * 2}k",
        "-preset", "veryfast",
        "-c:a", "aac", "-b:a", "128k",
        out_path_hd
    ]
    
    subprocess.run(cmd_hd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    
    # Check if HD version fits within limit
    if os.path.exists(out_path_hd):
        hd_size_mb = os.path.getsize(out_path_hd) / (1024 * 1024)
        log.info(f"Pass 1 result: {hd_size_mb:.2f}MB")
        
        if hd_size_mb <= target_size_mb:
            # Success! HD version fits
            log.info(f"‚úÖ Full HD compression successful: {hd_size_mb:.2f}MB")
            return out_path_hd
        else:
            # HD version too large, need to reduce resolution
            log.info(f"‚ö†Ô∏è HD version too large ({hd_size_mb:.2f}MB), reducing to 720p...")
            # Clean up HD attempt
            try:
                os.remove(out_path_hd)
            except:
                pass
    
    # PASS 2: Compress with 720p resolution
    log.info("Pass 2: Compressing with 720p resolution...")
    out_path_720 = os.path.join(dir_name, f"{base_name}_compressed.mp4")
    
    # Determine scale filter for 720p
    scale_filter = ""
    if width and height:
        if width > height:  # Landscape
            scale_filter = "scale=-2:720"
        else:  # Portrait or square
            scale_filter = "scale=720:-2"
        log.info(f"Scaling from {width}x{height} to 720p")
    
    cmd_720 = [
        ff, "-y", "-i", input_path,
        "-c:v", "libx264",
        "-b:v", f"{video_bitrate_kbit}k",
        "-maxrate", f"{video_bitrate_kbit * 1.5}k",
        "-bufsize", f"{video_bitrate_kbit * 2}k",
        "-preset", "veryfast",
        "-c:a", "aac", "-b:a", "128k"
    ]
    
    # Add scale filter
    if scale_filter:
        cmd_720.insert(4, "-vf")
        cmd_720.insert(5, scale_filter)
    
    cmd_720.append(out_path_720)
    
    subprocess.run(cmd_720, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    
    if os.path.exists(out_path_720):
        size_720_mb = os.path.getsize(out_path_720) / (1024 * 1024)
        log.info(f"‚úÖ 720p compression complete: {size_720_mb:.2f}MB")
        return out_path_720
    
    # If both failed, return original
    return input_path
    return input_path

# --- –§—É–Ω–∫—Ü—ñ—ó Telegram –ë–æ—Ç–∞ ---

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤—ñ—Ç! –ù–∞–¥—ñ—à–ª—ñ—Ç—å –º–µ–Ω—ñ –≤—ñ–¥–µ–æ –∞–±–æ –∞—É–¥—ñ–æ –¥–ª—è –æ–±—Ä–æ–±–∫–∏.")
    context.user_data.clear()
    return ConversationHandler.END

async def handle_new_video_button(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–æ–±–∫–∞ –∫–Ω–æ–ø–∫–∏ '–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–æ–≤–µ –≤—ñ–¥–µ–æ'."""
    query = update.callback_query
    await query.answer()
    await query.edit_message_text("–î–æ–±—Ä–µ! –ù–∞–¥—ñ—à–ª—ñ—Ç—å –Ω–æ–≤–µ –≤—ñ–¥–µ–æ –∞–±–æ –∞—É–¥—ñ–æ. üì§")
    context.user_data.clear()
    return ConversationHandler.END

async def handle_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    video_input = message.video or message.document
    
    if not video_input:
        await message.reply_text("–ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª—ñ—Ç—å –≤—ñ–¥–µ–æ—Ñ–∞–π–ª.")
        return STATE_RECEIVE_VIDEO if context.user_data else ConversationHandler.END

    try:
        # Check file size BEFORE attempting download
        # Telegram Bot API has 20MB limit for get_file()
        file_size_mb = video_input.file_size / (1024 * 1024) if hasattr(video_input, 'file_size') and video_input.file_size else 0
        
        if file_size_mb > 20:
            await message.reply_text(
                f"‚ùå **–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π!**\n\n"
                f"üìä –†–æ–∑–º—ñ—Ä: {file_size_mb:.1f} MB\n"
                f"‚ö†Ô∏è –û–±–º–µ–∂–µ–Ω–Ω—è Telegram Bot API: 20 MB\n\n"
                f"**–†—ñ—à–µ–Ω–Ω—è:**\n"
                f"1Ô∏è‚É£ –°—Ç–∏—Å–Ω—ñ—Ç—å –≤—ñ–¥–µ–æ –ø–µ—Ä–µ–¥ –≤—ñ–¥–ø—Ä–∞–≤–∫–æ—é\n"
                f"2Ô∏è‚É£ –ù–∞–¥—ñ—à–ª—ñ—Ç—å –∫–æ—Ä–æ—Ç—à–µ –≤—ñ–¥–µ–æ\n"
                f"3Ô∏è‚É£ –ó–º–µ–Ω—à—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª—å–Ω—ñ—Å—Ç—å (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –¥–æ 720p)\n\n"
                f"_–¶–µ –æ–±–º–µ–∂–µ–Ω–Ω—è Telegram, –Ω–∞ –∂–∞–ª—å –Ω–µ –º–æ–∂—É –π–æ–≥–æ –æ–±—ñ–π—Ç–∏_ üòî",
                parse_mode='Markdown'
            )
            return ConversationHandler.END
        
        file_name = video_input.file_name or "video.mp4"
        await message.reply_text("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –≤—ñ–¥–µ–æ... ‚è≥")

        new_file = await context.bot.get_file(video_input.file_id)
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{file_name}") as tmp_video_file:
            tmp_video_file_name = tmp_video_file.name
            await new_file.download_to_drive(tmp_video_file_name)
        
        # [!!! –ó–ú–Ü–ù–ï–ù–û –¢–ï–ö–°–¢ !!!]
        await message.reply_text("–í–∏—Ç—è–≥—É—é –∞—É–¥—ñ–æ —Ç–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞—é —Ç–µ–∫—Å—Ç... üöÄ")
        
        ff = find_ffmpeg()
        audio_path = tmp_video_file_name + ".mp3"
        subprocess.run([ff, "-i", tmp_video_file_name, "-vn", "-acodec", "libmp3lame", "-q:a", "4", "-y", audio_path], 
                       stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

        try:
            original_text, all_words = transcribe_with_groq(audio_path)
        except Exception as e:
            log.error(f"–ü–æ–º–∏–ª–∫–∞ Groq: {e}")
            await message.reply_text(f"–ü–æ–º–∏–ª–∫–∞ API: {e}")
            return ConversationHandler.END
        finally:
            if os.path.exists(audio_path): os.remove(audio_path)

        if not all_words:
            await message.reply_text("–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑–ø—ñ–∑–Ω–∞—Ç–∏ —Ç–µ–∫—Å—Ç. üò¢")
            return ConversationHandler.END

        # [FIX] Keep punctuation! User needs it in chat, and layout needs it for sentence breaks
        clean_text = original_text 

        context.user_data['video_path'] = tmp_video_file_name
        context.user_data['all_words'] = all_words
        context.user_data['clean_text'] = clean_text 
        
        # Load saved settings
        saved_settings = load_settings(message.chat_id)
        
        context.user_data['style_fontsize'] = saved_settings.get('fontsize', 93)
        context.user_data['style_color_name'] = saved_settings.get('color_name', '–ë—ñ–ª–∏–π')
        context.user_data['style_color_value'] = saved_settings.get('color_value', '&H00FFFFFF')
        context.user_data['style_font_name'] = saved_settings.get('font_name', STYLE_FONTS[0])
        context.user_data['style_margin_bottom'] = saved_settings.get('margin_bottom', 30)
        context.user_data['style_shadow_enabled'] = saved_settings.get('shadow_enabled', True)
        context.user_data['style_outline_enabled'] = saved_settings.get('outline_enabled', True)
        context.user_data['style_wpl'] = saved_settings.get('wpl', WORDS_PER_LINE)
        context.user_data['style_max_lines'] = saved_settings.get('max_lines', MAX_LINES_PER_PAGE)
        context.user_data['style_animation'] = saved_settings.get('animation', False)
        context.user_data['style_karaoke'] = saved_settings.get('karaoke', False)
        context.user_data['style_highlight_color_name'] = saved_settings.get('highlight_color_name', '–ñ–æ–≤—Ç–∏–π')
        context.user_data['style_highlight_color_value'] = saved_settings.get('highlight_color_value', '&H0000FFFF')

        # [!!! –†–û–ó–ë–ò–¢–¢–Ø –î–û–í–ì–û–ì–û –¢–ï–ö–°–¢–£ !!!]
        await message.reply_text(
            f"–û—Å—å —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–∏–π —Ç–µ–∫—Å—Ç –∑ –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—î—é.\n\n"
            f"üëâ –ù–∞–¥—ñ—à–ª—ñ—Ç—å –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç (–ø–æ–¥–≤—ñ–π–Ω–∏–π –ø—Ä–æ–±—ñ–ª - –Ω–æ–≤–∏–π —Ä—è–¥–æ–∫) –∞–±–æ '–û–ö'.\n\n"
            f"üìã –¢–µ–∫—Å—Ç –¥–ª—è –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è –Ω–∏–∂—á–µ üëá",
            parse_mode='Markdown'
        )
        
        if len(clean_text) > 4000:
            for i in range(0, len(clean_text), 4000):
                await message.reply_text(f"```\n{clean_text[i:i+4000]}\n```", parse_mode='Markdown')
        else:
            await message.reply_text(f"```\n{clean_text}\n```", parse_mode='Markdown')
        
        text_menu, keyboard = _get_settings_menu(context.user_data, 'main')
        await message.reply_text(text_menu, reply_markup=keyboard, parse_mode='Markdown')

        return STATE_RECEIVE_EDIT

    except Exception as e:
        log.error(f"–ü–æ–º–∏–ª–∫–∞ (handle_video): {e}", exc_info=True)
        await message.reply_text("–°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ –≤—ñ–¥–µ–æ.")
        return ConversationHandler.END

async def handle_audio_transcription(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = update.message
    audio_input = message.audio or (message.document if message.document and 'audio' in message.document.mime_type else None) or message.voice
    
    if not audio_input:
        await message.reply_text("–ù–∞–¥—ñ—à–ª—ñ—Ç—å –∞—É–¥—ñ–æ—Ñ–∞–π–ª –∞–±–æ –≥–æ–ª–æ—Å–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è.")
        return

    try:
        await message.reply_text("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –∞—É–¥—ñ–æ... ‚è≥")
        new_file = await context.bot.get_file(audio_input.file_id)
        file_name = getattr(audio_input, 'file_name', 'voice.ogg') or 'audio.mp3'
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{file_name}") as tmp_audio_file:
            tmp_path = tmp_audio_file.name
            await new_file.download_to_drive(tmp_path)
            
        # [!!! –ó–ú–Ü–ù–ï–ù–û –¢–ï–ö–°–¢ !!!]
        await message.reply_text("–†–æ–∑–ø—ñ–∑–Ω–∞—é —Ç–µ–∫—Å—Ç... üöÄ")

        original_text, _ = transcribe_with_groq(tmp_path) 
        clean_text = re.sub(r"[^\w\s']+", "", original_text).lower() 

        await message.reply_text(f"‚úÖ **–ì–æ—Ç–æ–≤–æ!**\n\n–¢–µ–∫—Å—Ç –¥–ª—è –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è üëá", parse_mode='Markdown')
        
        if len(clean_text) > 4000:
            for i in range(0, len(clean_text), 4000):
                await message.reply_text(clean_text[i:i+4000])
        else:
            await message.reply_text(f"{clean_text}")

        if os.path.exists(tmp_path): os.remove(tmp_path)

    except Exception as e:
        log.error(f"–ü–æ–º–∏–ª–∫–∞ –∞—É–¥—ñ–æ: {e}")
        await message.reply_text(f"–ü–æ–º–∏–ª–∫–∞: {e}")

async def handle_edit(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_reply = update.message.text
    clean_text = context.user_data.get('clean_text')

    if user_reply.lower() in ['–æ–∫–µ–π', '–æ–∫', 'ok']:
        text_to_process = clean_text
    else:
        text_to_process = user_reply
        
    context.user_data['text_to_process'] = text_to_process
    
    # Show menu again with updated text confirmation
    await update.message.reply_text("–¢–µ–∫—Å—Ç –ø—Ä–∏–π–Ω—è—Ç–æ! –ù–∞–ª–∞—à—Ç—É–π—Ç–µ —Å—Ç–∏–ª—å —ñ –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å '–ì–æ—Ç–æ–≤–æ'. üëá")
    text_menu, keyboard = _get_settings_menu(context.user_data, 'main')
    await update.message.reply_text(text_menu, reply_markup=keyboard, parse_mode='Markdown')
    return STATE_RECEIVE_EDIT

async def run_processing(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Executed when user clicks 'Done'.
    """
    video_path = context.user_data.get('video_path')
    all_words = context.user_data.get('all_words')
    text_to_process = context.user_data.get('text_to_process', context.user_data.get('clean_text'))
    
    tmp_dir = None 
    keep_files_flag = False
    
    # Determine chat_id/message_id for reply
    if update.message:
        chat_id = update.message.chat_id
        reply_to = update.message.message_id
    else:
        chat_id = update.effective_chat.id
        reply_to = None # Callback query doesn't have a message ID to reply to in the same way

    try:
        if not video_path or not all_words:
            await context.bot.send_message(chat_id, "–ü–æ–º–∏–ª–∫–∞ —Å—Ç–∞–Ω—É. –ù–∞–¥—ñ—à–ª—ñ—Ç—å –≤—ñ–¥–µ–æ –∑–Ω–æ–≤—É.")
            return

        style_settings = {
            'fontsize': context.user_data.get('style_fontsize', 93),
            'fontcolor': context.user_data.get('style_color_value', '&H00FFFFFF'),
            'fontname': context.user_data.get('style_font_name', STYLE_FONTS[0]),
            'margin_bottom': context.user_data.get('style_margin_bottom', 30),
            'shadow_enabled': context.user_data.get('style_shadow_enabled', True),
            'outline_enabled': context.user_data.get('style_outline_enabled', True),
            'wpl': context.user_data.get('style_wpl', 2),
            'max_lines': context.user_data.get('style_max_lines', 1),
            'animation': context.user_data.get('style_animation', False),
            'karaoke': context.user_data.get('style_karaoke', False),
            'highlight_color_value': context.user_data.get('style_highlight_color_value', '&H0000FFFF')
        }

        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –æ–±—Ä–æ–±–∫—É –≤ –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
        loop = asyncio.get_running_loop()
        
        # Force GC before heavy operation
        gc.collect()
        
        processed_path, tmp_dir = await loop.run_in_executor(
            None,
            process_video_with_edits, 
            video_path, 
            all_words, 
            text_to_process, 
            DEFAULT_CRF,
            style_settings 
        )
        
        # Force GC after heavy operation
        gc.collect()
        
        context.user_data['tmp_dir'] = tmp_dir

        processed_file_size_mb = os.path.getsize(processed_path) / (1024 * 1024)
        
        if processed_file_size_mb > 49.0:
            log.warning(f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π: {processed_file_size_mb:.2f} MB. –ü–æ—á–∏–Ω–∞—é —Å—Ç–∏—Å–Ω–µ–Ω–Ω—è...")
            await context.bot.send_message(chat_id, "–§–∞–π–ª –≤–µ–ª–∏–∫–∏–π (>50MB). –°—Ç–∏—Å–∫–∞—é, —â–æ–± –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏... üìâ")
            
            # Run compression
            compressed_path = await loop.run_in_executor(
                None, 
                compress_video, 
                processed_path, 
                48.0 # Target slightly less than 49 to be safe
            )
            
            # Check new size
            new_size_mb = os.path.getsize(compressed_path) / (1024 * 1024)
            if new_size_mb > 49.5:
                 log.warning(f"–°—Ç–∏—Å–Ω–µ–Ω–Ω—è –Ω–µ –¥–æ–ø–æ–º–æ–≥–ª–æ: {new_size_mb:.2f} MB")
                 await context.bot.send_message(
                    chat_id=chat_id,
                    text=f"‚ùå **–ù–µ –≤–¥–∞–ª–æ—Å—è —Å—Ç–∏—Å–Ω—É—Ç–∏ –¥–æ—Å—Ç–∞—Ç–Ω—å–æ.**\n–†–æ–∑–º—ñ—Ä: {new_size_mb:.2f} –ú–ë.\n`{compressed_path}`",
                    parse_mode='Markdown'
                )
                 keep_files_flag = True
            else:
                log.info(f"–°—Ç–∏—Å–Ω—É—Ç–æ –¥–æ {new_size_mb:.2f} MB")
                await context.bot.send_video(
                    chat_id=chat_id,
                    video=open(compressed_path, 'rb'),
                    filename=os.path.basename(compressed_path),
                    read_timeout=120, 
                    write_timeout=120, 
                    connect_timeout=120
                )
        else:
            await context.bot.send_message(chat_id, "–ì–æ—Ç–æ–≤–æ! –ù–∞–¥—Å–∏–ª–∞—é –≤—ñ–¥–µ–æ... ‚è≥üöÄ")
            await context.bot.send_video(
                chat_id=chat_id,
                video=open(processed_path, 'rb'),
                filename=os.path.basename(processed_path),
                read_timeout=120, 
                write_timeout=120, 
                connect_timeout=120
            )
            log.info(f"–í—ñ–¥–µ–æ –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ: {chat_id}")

            # --- [BUTTON FOR SUBTITLES] ---
            # Don't clean up yet. Offer to download subtitles.
            keyboard = [
                [InlineKeyboardButton("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –ª–∏—à–µ —Å—É–±—Ç–∏—Ç—Ä–∏", callback_data='download_subs')],
                [InlineKeyboardButton("‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç–∏", callback_data='cancel_cleanup')]
            ]
            await context.bot.send_message(
                chat_id=chat_id,
                text="–Ø–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏ –æ–∫—Ä–µ–º–æ (–¥–ª—è –º–æ–Ω—Ç–∞–∂—É), –Ω–∞—Ç–∏—Å–Ω—ñ—Ç—å –∫–Ω–æ–ø–∫—É –Ω–∏–∂—á–µ. üëá",
                reply_markup=InlineKeyboardMarkup(keyboard)
            )
            # ------------------------------

    except Exception as e:
        log.error(f"–ü–æ–º–∏–ª–∫–∞ (run_processing): {e}", exc_info=True)
        await context.bot.send_message(chat_id=chat_id, text=f"–ü–æ–º–∏–ª–∫–∞: {e}")
        # If error, cleanup now
        video_path = context.user_data.get('video_path')
        if video_path and os.path.exists(video_path):
            os.remove(video_path)
        tmp_dir = context.user_data.get('tmp_dir')
        if tmp_dir and os.path.exists(tmp_dir):
            shutil.rmtree(tmp_dir)
        context.user_data.clear()

def generate_green_screen_video(original_video_path, ass_path):
    """
    Generates a green screen video with burnt-in subtitles.
    Resolution and duration match the original video.
    """
    duration = get_video_duration(original_video_path)
    width, height = get_video_resolution(original_video_path)
    
    if not width or not height or duration == 0:
        log.error("Failed to get video props for green screen")
        return None

    ff = find_ffmpeg()
    
    # Create green background
    # color=c=0x00FF00:s={width}x{height}:d={duration}
    # Then burn subtitles
    
    sub_escaped = escape_for_subtitles_filter(ass_path)
    fontsdir_path = os.path.abspath("fonts")
    fontsdir_escaped = escape_for_subtitles_filter(fontsdir_path)
    
    vf_filter = ""
    if os.path.exists(fontsdir_path):
        vf_filter = f"subtitles='{sub_escaped}':fontsdir='{fontsdir_escaped}'"
    else:
        vf_filter = f"subtitles='{sub_escaped}'"

    # Input 0: Green generated video
    # Since we can't easily pipe generated video into complex filters in one go without -f lavfi
    # We use -f lavfi -i color=...
    
    dir_name = os.path.dirname(ass_path)
    out_path = os.path.join(dir_name, "chromakey_subtitles.mp4")
    
    cmd = [
        ff, "-y",
        "-f", "lavfi", "-i", f"color=c=0x00FF00:s={width}x{height}:d={duration}",
        "-f", "lavfi", "-i", "anullsrc=channel_layout=stereo:sample_rate=44100", # Silent audio
        "-vf", vf_filter,
        "-c:v", "libx264", "-preset", "superfast", "-pix_fmt", "yuv420p", "-profile:v", "main",
        "-c:a", "aac", "-shortest", # Audio encoding
        "-movflags", "+faststart",
        out_path
    ]
    
    log.info(f"Generating Green Screen: {' '.join(cmd)}")
    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    
    if os.path.exists(out_path):
        return out_path
    return None

async def handle_download_subs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    chat_id = query.message.chat_id
    tmp_dir = context.user_data.get('tmp_dir')
    video_path = context.user_data.get('video_path') # Original input video
    
    if not tmp_dir or not os.path.exists(tmp_dir):
        await query.edit_message_text("‚ùå –°–µ—Å—ñ—è –∑–∞—Å—Ç–∞—Ä—ñ–ª–∞. –ë—É–¥—å –ª–∞—Å–∫–∞, –ø–æ—á–Ω—ñ—Ç—å —Å–ø–æ—á–∞—Ç–∫—É.")
        return ConversationHandler.END

    ass_path = os.path.join(tmp_dir, "subs.ass")
    
    if not os.path.exists(ass_path):
        await query.edit_message_text("‚ùå –§–∞–π–ª —Å—É–±—Ç–∏—Ç—Ä—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
        return ConversationHandler.END

    await query.edit_message_text("‚è≥ –ì–µ–Ω–µ—Ä—É—é —Å—É–±—Ç–∏—Ç—Ä–∏ –Ω–∞ –∑–µ–ª–µ–Ω–æ–º—É —Ñ–æ–Ω—ñ...")
    
    # Run generation in executor
    loop = asyncio.get_running_loop()
    gs_video_path = await loop.run_in_executor(
        None, 
        generate_green_screen_video, 
        video_path, 
        ass_path
    )
    
    if gs_video_path and os.path.exists(gs_video_path):
        await context.bot.send_video(
            chat_id=chat_id,
            video=open(gs_video_path, 'rb'),
            width=get_video_resolution(video_path)[0],
            height=get_video_resolution(video_path)[1],
            caption="–ù–∞–∫–ª–∞–¥—ñ—Ç—å —Å—É–±—Ç–∏—Ç—Ä–∏ –ø–æ–≤–µ—Ä—Ö –≤—ñ–¥–µ–æ —É –≤—ñ–¥–µ–æ—Ä–µ–¥–∞–∫—Ç–æ—Ä—ñ —Ç–∞ –≤–∏–±–µ—Ä—ñ—Ç—å \"–•—Ä–æ–º–∞–∫–µ–π\". –ì–æ—Ç–æ–≤–æ!",
            read_timeout=120, write_timeout=120, connect_timeout=120
        )
    else:
        await context.bot.send_message(chat_id, "‚ùå –ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–µ–æ.")

    # Cleanup
    if video_path and os.path.exists(video_path):
        try: os.remove(video_path)
        except: pass
    if tmp_dir and os.path.exists(tmp_dir):
        try: shutil.rmtree(tmp_dir)
        except: pass
    context.user_data.clear()
    
    # await query.edit_message_text("‚úÖ –ì–æ—Ç–æ–≤–æ!") # Can't edit after cleanup potentially, or just leave last message
    return ConversationHandler.END

async def handle_cancel_cleanup(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    
    video_path = context.user_data.get('video_path')
    tmp_dir = context.user_data.get('tmp_dir')
    
    if video_path and os.path.exists(video_path):
        try: os.remove(video_path)
        except: pass
    if tmp_dir and os.path.exists(tmp_dir):
        try: shutil.rmtree(tmp_dir)
        except: pass
    context.user_data.clear()
    
    await query.edit_message_text("‚úÖ –†–æ–±–æ—Ç—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ, —Ñ–∞–π–ª–∏ –≤–∏–¥–∞–ª–µ–Ω–æ.")
    return ConversationHandler.END

# --- –°—Ç–∏–ª—ñ —Ç–∞ –ú–µ–Ω—é ---

STYLE_COLORS = {
    '–ë—ñ–ª–∏–π': '&H00FFFFFF',
    '–ñ–æ–≤—Ç–∏–π': '&H0000FFFF',
    '–ß–µ—Ä–≤–æ–Ω–∏–π': '&H000000FF',
    '–ó–µ–ª–µ–Ω–∏–π': '&H0000FF00',
    '–°–∏–Ω—ñ–π': '&H00FF0000',
}
COLOR_NAMES = list(STYLE_COLORS.keys())

# Highlight colors for karaoke (optimized for visibility)
HIGHLIGHT_COLORS = {
    '–ñ–æ–≤—Ç–∏–π': ('&H0000FFFF', 'üü®'),
    '–ß–µ—Ä–≤–æ–Ω–∏–π': ('&H000000FF', 'üü•'),
    '–ë–ª–∞–∫–∏—Ç–Ω–∏–π': ('&H00FFFF00', 'üü¶'),
    '–ó–µ–ª–µ–Ω–∏–π': ('&H0000FF00', 'üü©'),
    '–†–æ–∂–µ–≤–∏–π': ('&H00FF00FF', 'üü™'),
    '–ü–æ–º–∞—Ä–∞–Ω—á–µ–≤–∏–π': ('&H000099FF', 'üüß'),
    '–§—ñ–æ–ª–µ—Ç–æ–≤–∏–π': ('&H00FF0080', 'üü£'),
    '–õ–∞–π–º–æ–≤–∏–π': ('&H0000FF99', 'üíö'),
    '–ó–æ–ª–æ—Ç–∏–π': ('&H0000D7FF', 'üî∂'),
    '–ë—ñ–ª–∏–π': ('&H00FFFFFF', '‚¨ú'),
    '–°–∞–ª–∞—Ç–æ–≤–∏–π': ('&H0066FF99', 'üü¢'),
}
HIGHLIGHT_COLOR_NAMES = list(HIGHLIGHT_COLORS.keys())

# Font colors with emojis
STYLE_COLORS_EMOJI = {
    '–ë—ñ–ª–∏–π': ('&H00FFFFFF', '‚¨ú'),
    '–ñ–æ–≤—Ç–∏–π': ('&H0000FFFF', 'üü®'),
    '–ß–µ—Ä–≤–æ–Ω–∏–π': ('&H000000FF', 'üü•'),
    '–ó–µ–ª–µ–Ω–∏–π': ('&H0000FF00', 'üü©'),
    '–°–∏–Ω—ñ–π': ('&H00FF0000', 'üü¶'),
}

STYLE_FONTS = [
    "Peace Sans",
    "Impact",
    "OpenSans-Light",
    "Franklin Gothic Heavy"
]

MARGIN_OPTIONS = [10, 15, 20, 25, 30, 40]

# --- UI & MENUS ---

def _get_settings_menu(user_data, menu_state='main'):
    """
    Generates text and keyboard for different menu states:
    'main', 'style', 'layout', 'effects'
    """
    # Load current values
    fontsize = user_data.get('style_fontsize', 93)
    color_name = user_data.get('style_color_name', '–ë—ñ–ª–∏–π')
    font_name = user_data.get('style_font_name', 'Peace Sans')
    margin = user_data.get('style_margin_bottom', 30)
    
    shadow = "‚úÖ" if user_data.get('style_shadow_enabled', True) else "‚ùå"
    outline = "‚úÖ" if user_data.get('style_outline_enabled', True) else "‚ùå"
    
    wpl = user_data.get('style_wpl', WORDS_PER_LINE)
    max_lines = user_data.get('style_max_lines', MAX_LINES_PER_PAGE)
    
    anim = "‚úÖ" if user_data.get('style_animation', False) else "‚ùå"
    karaoke = "‚úÖ" if user_data.get('style_karaoke', False) else "‚ùå"
    highlight_color = user_data.get('style_highlight_color_name', '–ñ–æ–≤—Ç–∏–π')
    
    text = ""
    keyboard = []

    if menu_state == 'main':
        text = (
            f"‚öôÔ∏è **–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—É–±—Ç–∏—Ç—Ä—ñ–≤**\n\n"
            f"üé® –°—Ç–∏–ª—å: {font_name}, {fontsize}, {color_name}\n"
            f"üìê –ú–∞–∫–µ—Ç: {wpl} —Å–ª—ñ–≤/—Ä—è–¥, {max_lines} —Ä—è–¥/—Å—Ç–æ—Ä\n"
            f"‚ú® –ï—Ñ–µ–∫—Ç–∏: –ê–Ω—ñ–º {anim}, –ö–∞—Ä–∞–æ–∫–µ {karaoke}\n"
        )
        keyboard = [
            [InlineKeyboardButton("üé® –°—Ç–∏–ª—å", callback_data='menu_style'),
             InlineKeyboardButton("üìê –ú–∞–∫–µ—Ç", callback_data='menu_layout')],
            [InlineKeyboardButton("‚ú® –ï—Ñ–µ–∫—Ç–∏", callback_data='menu_effects')],
            [InlineKeyboardButton("‚úÖ –ì–æ—Ç–æ–≤–æ (–û–±—Ä–æ–±–∏—Ç–∏)", callback_data='process_done')],
            [InlineKeyboardButton("‚ùå –°–∫–∞—Å—É–≤–∞—Ç–∏", callback_data='new_video')]
        ]

    elif menu_state == 'style':
        text = (
            f"üé® **–°—Ç–∏–ª—å**\n\n"
            f"–®—Ä–∏—Ñ—Ç: {font_name}\n"
            f"–†–æ–∑–º—ñ—Ä: {fontsize}\n"
            f"–ö–æ–ª—ñ—Ä: {color_name}\n"
            f"–¢—ñ–Ω—å: {shadow} | –û–±–≤–æ–¥–∫–∞: {outline}"
        )
        # Create color buttons
        color_buttons = []
        for cname, (cval, emoji) in STYLE_COLORS_EMOJI.items():
            color_buttons.append(InlineKeyboardButton(emoji, callback_data=f'pick_color_{cname}'))
        
        keyboard = [
            [InlineKeyboardButton("–®—Ä–∏—Ñ—Ç ‚Ä∫", callback_data='set_font_next')],
            [InlineKeyboardButton("- –†–æ–∑–º—ñ—Ä", callback_data='set_size_minus'),
             InlineKeyboardButton("+ –†–æ–∑–º—ñ—Ä", callback_data='set_size_plus')],
            color_buttons,
            [InlineKeyboardButton(f"–¢—ñ–Ω—å {shadow}", callback_data='toggle_shadow'),
             InlineKeyboardButton(f"–û–±–≤–æ–¥–∫–∞ {outline}", callback_data='toggle_outline')],
            [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='menu_main')]
        ]

    elif menu_state == 'layout':
        text = (
            f"üìê **–ú–∞–∫–µ—Ç**\n\n"
            f"–°–ª—ñ–≤ —É —Ä—è–¥–∫—É: {wpl}\n"
            f"–†—è–¥–∫—ñ–≤ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ: {max_lines}\n"
            f"–í—ñ–¥—Å—Ç—É–ø –∑–Ω–∏–∑—É: {margin}%"
        )
        keyboard = [
            [InlineKeyboardButton("- –°–ª–æ–≤–∞", callback_data='set_wpl_minus'),
             InlineKeyboardButton("+ –°–ª–æ–≤–∞", callback_data='set_wpl_plus')],
            [InlineKeyboardButton("- –†—è–¥–∫–∏", callback_data='set_lines_minus'),
             InlineKeyboardButton("+ –†—è–¥–∫–∏", callback_data='set_lines_plus')],
            [InlineKeyboardButton("- –í—ñ–¥—Å—Ç—É–ø", callback_data='set_margin_minus'),
             InlineKeyboardButton("+ –í—ñ–¥—Å—Ç—É–ø", callback_data='set_margin_plus')],
            [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='menu_main')]
        ]

    elif menu_state == 'effects':
        text = (
            f"‚ú® **–ï—Ñ–µ–∫—Ç–∏**\n\n"
            f"Pop-up –ê–Ω—ñ–º–∞—Ü—ñ—è: {anim}\n"
            f"–ö–∞—Ä–∞–æ–∫–µ (–ø—ñ–¥—Å–≤—ñ—Ç–∫–∞): {karaoke}\n"
            f"–ö–æ–ª—ñ—Ä –ø—ñ–¥—Å–≤—ñ—Ç–∫–∏: {highlight_color}\n"
            f"_(–ö–∞—Ä–∞–æ–∫–µ –∑–º—ñ–Ω—é—î –∫–æ–ª—ñ—Ä –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–ª–æ–≤–∞)_"
        )
        # Create highlight color buttons - split into 2 rows
        highlight_btns = []
        for cname, (cval, emoji) in HIGHLIGHT_COLORS.items():
            highlight_btns.append(InlineKeyboardButton(emoji, callback_data=f'pick_highlight_{cname}'))
        
        # Split into rows of 6
        row1 = highlight_btns[:6]
        row2 = highlight_btns[6:]
        
        keyboard = [
            [InlineKeyboardButton(f"–ê–Ω—ñ–º–∞—Ü—ñ—è {anim}", callback_data='toggle_anim')],
            [InlineKeyboardButton(f"–ö–∞—Ä–∞–æ–∫–µ {karaoke}", callback_data='toggle_karaoke')],
            row1,
            row2,
            [InlineKeyboardButton("üîô –ù–∞–∑–∞–¥", callback_data='menu_main')]
        ]

    return text, InlineKeyboardMarkup(keyboard)

async def handle_settings_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()
    data = query.data
    user_data = context.user_data
    
    # Navigation
    if data.startswith('menu_'):
        target = data.split('_')[1]
        text, markup = _get_settings_menu(user_data, target)
        await query.edit_message_text(text, reply_markup=markup, parse_mode='Markdown')
        return

    # Actions
    if data == 'process_done':
        # Trigger processing (simulate sending "OK")
        # We can't easily trigger the message handler, so we call the logic directly or ask user to confirm.
        # Better: Just say "Settings saved. Send 'OK' to process." or edit text to say "Processing..."
        # Actually, the user flow is: Send Video -> Send Text -> Menu -> (User clicks Done) -> Processing.
        # So we need to call the processing logic here.
        await query.edit_message_text("–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∑–±–µ—Ä–µ–∂–µ–Ω–æ! –ü–æ—á–∏–Ω–∞—é –æ–±—Ä–æ–±–∫—É... ‚öôÔ∏è")
        
        # We need to trigger handle_edit logic. 
        # Since handle_edit expects a Message update, we can't call it directly with CallbackQuery.
        # We will extract the logic to a helper or just run it here.
        # Let's call a helper function `run_processing(update, context)`
        
        # [!!! FIX: RUN IN BACKGROUND !!!]
        # Use create_task to prevent blocking the webhook response
        asyncio.create_task(run_processing(update, context))
        return ConversationHandler.END

    if data == 'new_video':
        await query.edit_message_text("–î—ñ—é —Å–∫–∞—Å–æ–≤–∞–Ω–æ. –ù–∞–¥—ñ—à–ª—ñ—Ç—å –Ω–æ–≤–µ –≤—ñ–¥–µ–æ. üì§")
        context.user_data.clear()
        return ConversationHandler.END

    # Font/Size Setters
    elif data == 'set_size_plus':
        current_size = user_data.get('style_fontsize', 93)
        user_data['style_fontsize'] = min(current_size + 5, 200)
        log.info(f"Font size increased to {user_data['style_fontsize']}")
    elif data == 'set_size_minus':
        current_size = user_data.get('style_fontsize', 93)
        user_data['style_fontsize'] = max(current_size - 5, 30)
        log.info(f"Font size decreased to {user_data['style_fontsize']}")
    elif data == 'set_font_next':
        current = user_data.get('style_font_name', STYLE_FONTS[0])
        idx = STYLE_FONTS.index(current) if current in STYLE_FONTS else 0
        user_data['style_font_name'] = STYLE_FONTS[(idx + 1) % len(STYLE_FONTS)]

    elif data == 'set_color_next':
        curr = user_data.get('style_color_name', '–ë—ñ–ª–∏–π')
        try: idx = COLOR_NAMES.index(curr)
        except: idx = 0
        idx = (idx + 1) % len(COLOR_NAMES)
        new_name = COLOR_NAMES[idx]
        user_data['style_color_name'] = new_name
        user_data['style_color_value'] = STYLE_COLORS[new_name]
    elif data == 'set_color_prev':
        curr = user_data.get('style_color_name', '–ë—ñ–ª–∏–π')
        try: idx = COLOR_NAMES.index(curr)
        except: idx = 0
        idx = (idx - 1) % len(COLOR_NAMES)
        new_name = COLOR_NAMES[idx]
        user_data['style_color_name'] = new_name
        user_data['style_color_value'] = STYLE_COLORS[new_name]

    elif data == 'toggle_shadow':
        user_data['style_shadow_enabled'] = not user_data.get('style_shadow_enabled', True)
    elif data == 'toggle_outline':
        user_data['style_outline_enabled'] = not user_data.get('style_outline_enabled', True)

    # Layout Setters
    elif data == 'set_wpl_plus':
        user_data['style_wpl'] = user_data.get('style_wpl', 2) + 1
    elif data == 'set_wpl_minus':
        user_data['style_wpl'] = max(1, user_data.get('style_wpl', 2) - 1)
    
    elif data == 'set_lines_plus':
        user_data['style_max_lines'] = user_data.get('style_max_lines', 1) + 1
    elif data == 'set_lines_minus':
        user_data['style_max_lines'] = max(1, user_data.get('style_max_lines', 1) - 1)

    elif data == 'set_margin_plus':
        user_data['style_margin_bottom'] = min(50, user_data.get('style_margin_bottom', 30) + 5)
    elif data == 'set_margin_minus':
        user_data['style_margin_bottom'] = max(0, user_data.get('style_margin_bottom', 30) - 5)

    # Effects Setters
    elif data == 'toggle_anim':
        user_data['style_animation'] = not user_data.get('style_animation', False)
    elif data == 'toggle_karaoke':
        user_data['style_karaoke'] = not user_data.get('style_karaoke', False)
    
    # Direct color pickers
    elif data.startswith('pick_color_'):
        color_name = data.replace('pick_color_', '')
        log.info(f"Color picker triggered: {color_name}, available: {list(STYLE_COLORS_EMOJI.keys())}")
        if color_name in STYLE_COLORS_EMOJI:
            user_data['style_color_name'] = color_name
            user_data['style_color_value'] = STYLE_COLORS_EMOJI[color_name][0]
            log.info(f"Set color to {color_name}: {STYLE_COLORS_EMOJI[color_name][0]}")
        else:
            log.warning(f"Color {color_name} not found in STYLE_COLORS_EMOJI")
    elif data.startswith('pick_highlight_'):
        color_name = data.replace('pick_highlight_', '')
        log.info(f"Highlight picker triggered: {color_name}, available: {list(HIGHLIGHT_COLORS.keys())}")
        if color_name in HIGHLIGHT_COLORS:
            user_data['style_highlight_color_name'] = color_name
            user_data['style_highlight_color_value'] = HIGHLIGHT_COLORS[color_name][0]
            log.info(f"Set highlight to {color_name}: {HIGHLIGHT_COLORS[color_name][0]}")
        else:
            log.warning(f"Highlight color {color_name} not found in HIGHLIGHT_COLORS")

    # Save settings
    current_settings = {
        'fontsize': user_data.get('style_fontsize'),
        'color_name': user_data.get('style_color_name'),
        'color_value': user_data.get('style_color_value'),
        'font_name': user_data.get('style_font_name'),
        'margin_bottom': user_data.get('style_margin_bottom'),
        'shadow_enabled': user_data.get('style_shadow_enabled'),
        'outline_enabled': user_data.get('style_outline_enabled'),
        'wpl': user_data.get('style_wpl'),
        'max_lines': user_data.get('style_max_lines'),
        'animation': user_data.get('style_animation'),
        'karaoke': user_data.get('style_karaoke'),
        'highlight_color_name': user_data.get('style_highlight_color_name'),
        'highlight_color_value': user_data.get('style_highlight_color_value')
    }
    save_settings(query.message.chat_id, current_settings)

    # Refresh current menu
    # Need to know which menu we are in. 
    # A simple hack is to check the button that was clicked or store state.
    # But since we don't store menu state in user_data, we can infer or just default to 'main' 
    # or try to guess. 
    # Better: Pass the menu state in callback data? e.g. 'set_size_plus:style'
    # For now, simple heuristic based on data prefix
    next_menu = 'main'
    if data.startswith('set_size') or data.startswith('set_color') or data.startswith('set_font') or data.startswith('toggle_shadow') or data.startswith('toggle_outline') or data.startswith('pick_color_'):
        next_menu = 'style'
    elif data.startswith('set_wpl') or data.startswith('set_lines') or data.startswith('set_margin'):
        next_menu = 'layout'
    elif data.startswith('toggle_anim') or data.startswith('toggle_karaoke') or data.startswith('set_highlight') or data.startswith('pick_highlight_'):
        next_menu = 'effects'
    
    text, markup = _get_settings_menu(user_data, next_menu)
    try:
        await query.edit_message_text(text, reply_markup=markup, parse_mode='Markdown')
    except Exception:
        pass



async def cancel_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–°–∫–∞—Å–æ–≤—É—î –ø–æ—Ç–æ—á–Ω—É –æ–ø–µ—Ä–∞—Ü—ñ—é —Ç–∞ —á–∏—Å—Ç–∏—Ç—å —Ñ–∞–π–ª–∏."""
    video_path = context.user_data.get('video_path')
    tmp_dir = context.user_data.get('tmp_dir')
    
    if video_path and os.path.exists(video_path):
        try: os.remove(video_path)
        except: pass
        
    if tmp_dir and os.path.exists(tmp_dir):
        try: shutil.rmtree(tmp_dir)
        except: pass
        
    context.user_data.clear()
    await update.message.reply_text("–î—ñ—é —Å–∫–∞—Å–æ–≤–∞–Ω–æ. ‚úÖ")
    return ConversationHandler.END

async def wait_for_network():
    """Waits for Telegram API to be reachable."""
    url = "https://api.telegram.org"
    retries = 0
    max_retries = 30  # Wait up to 2.5 minutes
    
    log.info("Checking network connectivity...")
    import httpx
    import socket
    
    while retries < max_retries:
        try:
            # Try DNS resolution first
            try:
                socket.gethostbyname("api.telegram.org")
            except socket.gaierror:
                log.warning(f"DNS lookup failed ({retries+1}/{max_retries})")
                
            async with httpx.AsyncClient(timeout=10.0) as client:
                await client.get(url)
                log.info("Network is UP! üöÄ")
                return
        except Exception as e:
            retries += 1
            log.warning(f"Network check failed ({retries}/{max_retries}): {e}")
            await asyncio.sleep(5)  # Wait 5 seconds between tries
            
    log.error("Network check failed after max retries. Proceeding anyway...")


def main():
    """Main function to start the bot"""
    if "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA" in TELEGRAM_BOT_TOKEN:
        log.error("–í–∫–∞–∂—ñ—Ç—å TELEGRAM_BOT_TOKEN!")
        sys.exit(1)
        
    log.info("–°—Ç–≤–æ—Ä—é—î–º–æ –¥–æ–¥–∞—Ç–æ–∫ –±–æ—Ç–∞...")
    application = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).connect_timeout(30).read_timeout(30).build()
    
    application.add_handler(MessageHandler(filters.AUDIO | filters.VOICE | filters.Document.AUDIO, handle_audio_transcription))

    conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler('start', start_command), 
            MessageHandler(filters.VIDEO | filters.Document.VIDEO, handle_video) 
        ],
        states={
            STATE_RECEIVE_EDIT: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_edit),
                CallbackQueryHandler(handle_settings_callback, pattern="^menu_|^set_|^toggle_|^pick_|^process_|^new_video")
            ],
        },
        fallbacks=[
            CommandHandler('start', start_command), 
            CommandHandler('cancel', cancel_command) 
        ],
    )
    application.add_handler(conv_handler)
    application.add_handler(CallbackQueryHandler(handle_download_subs, pattern="^download_subs$"))
    application.add_handler(CallbackQueryHandler(handle_cancel_cleanup, pattern="^cancel_cleanup$"))
    application.add_handler(CallbackQueryHandler(handle_new_video_button, pattern="^start_new$"))

    # Check for Render environment
    RENDER_EXTERNAL_URL = os.getenv("RENDER_EXTERNAL_URL")
    PORT = int(os.getenv("PORT", "7860"))

    if RENDER_EXTERNAL_URL:
        # Webhook mode for Render/Hugging Face
        log.info(f"Running in webhook mode on port {PORT}")
        log.info("Starting bot...")
        application.run_webhook(
            listen="0.0.0.0",
            port=PORT,
            url_path="",
            webhook_url=RENDER_EXTERNAL_URL
        )
    else:
        log.info("Running in polling mode...")
        application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
